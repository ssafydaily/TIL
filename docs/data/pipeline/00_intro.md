# 소개
> [원문보기](https://www.ibm.com/kr-ko/topics/data-pipeline)

## 데이터 파이프라인 유형

- 데이터 파이프라인에는 몇 가지 주요 유형이 있으며, 각 유형은 특정 플랫폼의 특정 작업에 적합합니다. 

### 일괄 처리
- 일괄 처리 방식의 개발은 안정적이고 확장 가능한 데이터 인프라를 구축하는 데 중요한 단계였습니다. 
- 2004년에 일괄 처리 알고리즘인 MapReduce가 특허를 받은 후 Hadoop, CouchDB 및 MongoDB와 같은 오픈 소스 시스템에 통합되었습니다.
- 일괄 처리는 일반적으로 사용량이 적은 업무 시간에 예약되는 설정된 시간 간격 동안 저장소에 데이터 '배치(batch)'를 로드
- 일괄 처리 작업은 한 명령의 출력이 다음 명령의 입력이 되는 시퀀스된 명령의 워크플로우를 형성

### 스트리밍 데이터
- 스트리밍 데이터 파이프라인(이벤트 기반 아키텍처라고도 함)은 애플리케이션 내의 센서 또는 사용자 상호 작용과 같은 다양한 소스에서 생성된 이벤트를 지속적으로 처리
- 스트리밍 데이터는 데이터를 지속적으로 업데이트해야 할 때 활용
- 이벤트는 메시징 시스템 또는 메시지 브로커(예: 오픈 소스 제품인 Apache Kafka)를 통해 전송
- 일괄 처리 시스템보다 지연 시간이 짧지만, 안정적이지 못함.
  - 메시지가 의도치 않게 삭제되거나 대기열에서 오랜 시간을 보낼 수 있음.

### 데이터 통합 파이프 라인

- 여러 소스의 데이터를 단일 통합 뷰로 병합하는 데 집중합니다. 
- 이러한 파이프라인에는 데이터 웨어하우스 또는 데이터 레이크와 같은 중앙 집중식 저장소에 저장하기 전에 원시 데이터를 정리, 보강 또는 수정하는 ETL(추출, 변환 및 로드) 프로세스가 포함
- 호환되지 않는 형식이나 구조를 생성하는 서로 다른 시스템을 처리하는 데 필수적


## 아키텍쳐

1. 데이터 통합: 데이터는 서비스형 소프트웨어(SaaS) 플랫폼, 사물 인터넷(IoT) 디바이스 및 모바일 디바이스를 비롯한 다양한 소스, 그리고 다양한 데이터 구조(정형 및 비정형 데이터)에서 수집됩니다. 스트리밍 데이터 내에서 이러한 원시 데이터 소스은 일반적으로 생산자, 게시자 또는 발신자로 알려져 있습니다. 기업은 데이터를 처리할 준비가 된 경우에만 데이터를 추출하도록 선택할 수 있지만, 먼저 클라우드 데이터 웨어하우스 제공업체 내에 원시 데이터를 배치하는 것이 더 좋습니다. 이러한 방식으로 기업은 데이터 처리 작업을 조정해야 하는 경우 기록 데이터를 업데이트할 수 있습니다. 이 데이터 수집 프로세스 중에 데이터의 일관성과 정확성을 보장하기 위해 다양한 유효성 검사 및 확인 작업을 수행할 수 있습니다.

2. 데이터 변환: 이 단계에서는 대상 데이터 저장소에 필요한 형식으로 데이터를 처리하기 위해 일련의 작업이 실행됩니다. 이러한 작업에는 비즈니스 보고와 같은 반복적인 작업 스트림에 대한 자동화 및 거버넌스가 포함되어 있어 데이터가 일관되게 정리되고 변환되도록 합니다. 예를 들어 데이터 스트림은 중첩된 JSON 형식으로 제공될 수 있으며, 데이터 변환 단계에서는 해당 JSON을 언롤하여 분석을 위한 주요 필드를 추출하는 것을 목표로 합니다.

3. 데이터 저장: 변환된 데이터는 데이터 저장소에 저장되어 다양한 이해관계자에게 노출될 수 있습니다. 스트리밍 데이터 내에서 이 변환된 데이터는 일반적으로 소비자, 구독자 또는 수신자로 알려져 있습니다.  
